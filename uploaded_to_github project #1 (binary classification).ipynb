{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"project #1 (binary classification).ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"B2GbTyHalDo-","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":"OK"}},"base_uri":"https://localhost:8080/","height":167},"outputId":"42d1e771-1af9-46a5-a480-8ea14a433619","executionInfo":{"status":"ok","timestamp":1527509046562,"user_tz":-300,"elapsed":17611,"user":{"displayName":"Hamza Amir","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112301600399689865426"}}},"cell_type":"code","source":["#@title Default title text\n","import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","# Install Keras with pip\n","!pip install -q keras\n","import keras\n","# Install GraphViz with apt\n","!apt-get install graphviz -y\n","from google.colab import files\n","uploaded = files.upload()\n","import pandas as pd\n","import io\n","dataframe = pd.read_csv('sonar.csv', header=None)\n"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","graphviz is already the newest version (2.38.0-16ubuntu2).\n","0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/html":["\n","     <input type=\"file\" id=\"files-eaa3070e-18a0-47bd-b851-fbb932e06eb9\" name=\"files[]\" multiple disabled />\n","     <output id=\"result-eaa3070e-18a0-47bd-b851-fbb932e06eb9\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Saving project #1 (sonar).ipynb to project #1 (sonar) (1).ipynb\n"],"name":"stdout"}]},{"metadata":{"id":"jNc2qJ1-kwuF","colab_type":"text"},"cell_type":"markdown","source":["# Step 2. Baseline Neural Network Model Performance\n","## Letâ€™s create a baseline model and result for this project."]},{"metadata":{"id":"XuVlEZ3ukwuK","colab_type":"text"},"cell_type":"markdown","source":["### We will start off by importing all of the classes and functions we will need:"]},{"metadata":{"id":"8EoUKDzCkwuN","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["import numpy as np\n","import pandas\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import cross_val_score\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DfppaV3Vkwuk","colab_type":"text"},"cell_type":"markdown","source":["# Next, we can initialize the random number generator to ensure that we always get the same results when executing this code. This will help if we are debugging:"]},{"metadata":{"id":"jKizrNDdkwuo","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# fix random seed for reproducibility\n","seed = 7\n","np.random.seed(seed)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zqYqgRPvkwuz","colab_type":"text"},"cell_type":"markdown","source":["# Now we can load the dataset using pandas and split the columns into 60 input variables (X) and 1 output variable (Y). We use pandas to load the data because it easily handles strings (the output variable), whereas attempting to load the data directly using NumPy would be more difficult."]},{"metadata":{"id":"nb-1FzMXkwu1","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["# load dataset\n","dataframe = pandas.read_csv(\"sonar.csv\", header=None)\n","dataset = dataframe.values\n","# split into input (X) and output (Y) variables\n","X = dataset[:,0:60].astype(float)\n","Y = dataset[:,60]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KfUKMVr8kwu9","colab_type":"text"},"cell_type":"markdown","source":["# The output variable is string values. We must convert them into integer values 0 and 1."]},{"metadata":{"id":"tn6gfLdxkwu_","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["le = LabelEncoder()\n","Y =  le.fit_transform(Y)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5zb5KL7BkwvH","colab_type":"text"},"cell_type":"markdown","source":["### Letâ€™s start off by defining the function that creates our baseline model. Our model will have a single fully connected hidden layer with the same number of neurons as input variables. This is a good default starting point when creating neural networks.\n","### The weights are initialized using a small Gaussian random number. The Rectifier activation function is used. The output layer contains a single neuron in order to make predictions. It uses the sigmoid activation function in order to produce a probability output in the range of 0 to 1 that can easily and automatically be converted to crisp class values.\n","### Finally, we are using the logarithmic loss function (binary_crossentropy) during training, the preferred loss function for binary classification problems. The model also uses the efficient Adam optimization algorithm for gradient. descent and accuracy metrics will be collected when the model is trained.\n"]},{"metadata":{"id":"_fH4QAv0kwvL","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0}}},"cell_type":"code","source":["from keras import initializers\n","Gaussian = initializers.random_normal()\n","def create_baseline():\n","            # create model, write code below\n","            sonar_model = Sequential()\n","            sonar_model.add(Dense(60, kernel_initializer=Gaussian ,activation='relu', input_dim=60))\n","            sonar_model.add(Dense(1, activation='sigmoid'))\n","            # Compile model, write code below\n","            sonar_model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n","            return sonar_model"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9u8qThwCkwvX","colab_type":"text"},"cell_type":"markdown","source":["### Now it is time to evaluate this model using stratified cross validation in the scikit-learn framework."]},{"metadata":{"id":"yuw4lah-kwva","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"10b536ab-bd40-448f-e0d6-c70707a88750","executionInfo":{"status":"ok","timestamp":1527509500376,"user_tz":-300,"elapsed":259213,"user":{"displayName":"Hamza Amir","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112301600399689865426"}}},"cell_type":"code","source":["# evaluate model with standardized dataset\n","estimator = KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=4, verbose=0)\n","kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n","results = cross_val_score(estimator, X, Y, cv=kfold)\n","print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Results: 82.21% (3.14%)\n"],"name":"stdout"}]},{"metadata":{"id":"02kK42Ldkwvo","colab_type":"text"},"cell_type":"markdown","source":["# Step 3. Re-Run The Baseline Model With Data Preparation"]},{"metadata":{"id":"hOEB953nkwvq","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"abef10f8-5f5e-4c13-99c0-22950b8a5d58","executionInfo":{"status":"ok","timestamp":1527509768741,"user_tz":-300,"elapsed":268281,"user":{"displayName":"Hamza Amir","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112301600399689865426"}}},"cell_type":"code","source":["# evaluate baseline model with standardized dataset\n","np.random.seed(seed)\n","estimators = []\n","estimators.append(('standardize', StandardScaler()))\n","estimators.append(('mlp', KerasClassifier(build_fn=create_baseline, epochs=100, batch_size=4, verbose=0)))\n","pipeline = Pipeline(estimators)\n","kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n","results = cross_val_score(pipeline, X, Y, cv=kfold)\n","print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Standardized: 85.56% (7.22%)\n"],"name":"stdout"}]},{"metadata":{"id":"C80n17M7kwwA","colab_type":"text"},"cell_type":"markdown","source":["# Step 4. Tuning Layers and Number of Neurons in The Model"]},{"metadata":{"id":"wSjymLCjkwwB","colab_type":"text"},"cell_type":"markdown","source":["### 4.1. Evaluate a Smaller Network"]},{"metadata":{"id":"Xx4q4ioEkwwE","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"f73297ca-7aa2-46b1-ebd2-e2ae93c804c0","executionInfo":{"status":"ok","timestamp":1527510045967,"user_tz":-300,"elapsed":277040,"user":{"displayName":"Hamza Amir","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112301600399689865426"}}},"cell_type":"code","source":["def create_smaller():\n","    # create model\n","    sonar_model = Sequential()\n","    sonar_model.add(Dense(30, activation='relu', input_dim=60))\n","    sonar_model.add(Dense(1,activation='sigmoid'))\n","    # Compile model\n","    sonar_model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n","    return sonar_model\n","\n","\n","np.random.seed(seed)\n","estimators = []\n","estimators.append(('standardize', StandardScaler()))\n","estimators.append(('mlp', KerasClassifier(build_fn=create_smaller, epochs=100, batch_size=4, verbose=0)))\n","pipeline = Pipeline(estimators)\n","kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n","results = cross_val_score(pipeline, X, Y, cv=kfold)\n","print(\"Standardized: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Standardized: 85.06% (7.61%)\n"],"name":"stdout"}]},{"metadata":{"id":"5-9PyWSckwwP","colab_type":"text"},"cell_type":"markdown","source":["#  Step 4.2. Evaluate a Larger Network"]},{"metadata":{"id":"XqraM4NBkwwS","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"5d5fe9ba-9c0c-46fe-ae7b-638deea93c56","executionInfo":{"status":"ok","timestamp":1527510353475,"user_tz":-300,"elapsed":307241,"user":{"displayName":"Hamza Amir","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112301600399689865426"}}},"cell_type":"code","source":["def create_larger():\n","                # create model\n","                sonar_model = Sequential()\n","                sonar_model.add(Dense(60, activation='relu', input_dim=60))\n","                sonar_model.add(Dense(30, activation='relu'))\n","                sonar_model.add(Dense(1,  activation='sigmoid'))\n","                # Compile model\n","                sonar_model.compile(loss='binary_crossentropy',optimizer='adam', metrics=['accuracy'])\n","                return sonar_model\n","            \n","estimators = []\n","estimators.append(('standardize', StandardScaler()))\n","estimators.append(('mlp', KerasClassifier(build_fn=create_larger, epochs=100, batch_size=4, verbose=0)))\n","pipeline = Pipeline(estimators)\n","kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n","results = cross_val_score(pipeline, X, Y, cv=kfold)\n","print(\"Larger: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Larger: 84.04% (5.53%)\n"],"name":"stdout"}]},{"metadata":{"id":"dM8hEVyDkwxM","colab_type":"text"},"cell_type":"markdown","source":["# Step 7: Rewriting the code using the Keras Functional API"]},{"metadata":{"id":"xGOb5IpzkwxP","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"530ba5ed-b254-48e0-a40d-d3e3cc2a3b2c","executionInfo":{"status":"ok","timestamp":1527510385087,"user_tz":-300,"elapsed":31448,"user":{"displayName":"Hamza Amir","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112301600399689865426"}}},"cell_type":"code","source":["import keras\n","from keras import layers\n","def kera_api_model():\n","    # create model\n","                    inputs = keras.Input(shape=(60,))\n","                    x = layers.Dense(60, activation='relu')(inputs)\n","                    x = layers.Dense(10, activation='relu')(x)\n","                    outputs = layers.Dense(1, activation='sigmoid')(x)\n","\n","                    model = keras.Model(inputs, outputs)\n","                     # Compile model\n","                    model.compile(loss='binary_crossentropy', optimizer='adam',   metrics=['accuracy'])\n","                \n","                    return model\n","\n","estimators = []\n","estimators.append(('standardize', StandardScaler()))\n","# http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n","# StandardScaler:\n","# [TAJARBA] har column ki har value me sy us calumn ka mean <minus> kar deta h or phir har calumn k har value ko us \n","          # column ki  std sy divide kar deta h..\n","                        #mean_axis0 = np.mean(X[:, 0]) # pehly column ka mean ly lya\n","                        #std_axis0 = np.std(X[:, 0])                 # pehly column ka std ly lya\n","                        #X[:, 0] -= mean_axis0                                         # pehly column ki har value me sy pehly column ka mean minus kar dya\n","                        #X[:, 0] /= std_axis0                                                # pehly column ki har value ko pehly column k std sy divide kar dya\n","# Standardize features by removing the mean and scaling to unit variance.\n","# Centering and scaling happen independently on each feature by computing the relevant statistics on the samples in the training set. Mean \n","#and standard deviation are then stored to be used on later data using the transform` method.\n","estimators.append(('mlp', KerasClassifier(build_fn=kera_api_model, epochs=20, batch_size=4, verbose=0)))\n","#  KerasClassifier\n","# Implementation of the scikit-learn classifier API for Keras.\n","# Returns history  object details about the training history at each epoch.\n","#  Constructs a new model with `build_fn` & fit the model to `(x, y)`.\n","\n","# build_fn: callable function or class instance\n","#   https://keras.io/scikit-learn-api/\n","        # build_fn should construct, compile and return a Keras model, which will then be used to fit/predict. \n","        # One of the following three values could be passed to build_fn:\n","                        # A function\n","                        # An instance of a class that implements the __call__ method\n","                        # None. This means you implement a class that inherits from either KerasClassifier or KerasRegressor. The __call__ method of the present class will then be treated as the default build_fn.\n","\n","pipeline = Pipeline(estimators)\n","# Pipeline():\n","#  Sequentially apply a list of transforms and a final estimator. \n","# Intermediate steps of the pipeline must be 'transforms', that is, they must implement fit and transform methods.\n"," # The final estimator only needs to implement fit.\n"," # The transformers in the pipeline can be cached using ``memory`` argument.\n","\n","#The purpose of the pipeline is to assemble several steps that can be cross-validated together while setting different parameters.\n","# For this, it enables setting parameters of the various steps using their names and the parameter name separated by a '__', as in the example below.\n","# A step's estimator may be replaced entirely by setting the parameter with its name to another estimator, or a transformer removed by setting to None.\n","\n","#  steps : list\n","# List of (name, transform) tuples (implementing fit/transform) that are chained, in the order in which they are chained, with the last object\n","# an estimator.\n","kfold = StratifiedKFold(n_splits=4, shuffle=True, random_state=seed)\n","# StratifiedKFold: Stratified K-Folds cross-validator\n","#  Provides train/test indices to split data in train/test sets.  \n","# This cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for\n","# each class return:\n","#train : ndarray, The training set indices for that split.\n","# test : ndarray,  The testing set indices for that split.\n","results = cross_val_score(pipeline, X, Y, cv=kfold)\n","# http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html\n","# # cross_val_score:\n","# # cross_val_score(estimator, X, y=None, groups=None, scoring=None, cv=None, n_jobs=1, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n","# # estimator : estimator object implementing 'fit'. The object to use to fit the data.\n","# Returns: \n","            # scores : array of float, shape=(len(list(cv)),)\n","            # Array of scores of the estimator for each run of the cross validation.\n","\n","print(\"Smaller: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Smaller: 85.12% (1.91%)\n"],"name":"stdout"}]},{"metadata":{"id":"u6wz1ROpkwxo","colab_type":"text"},"cell_type":"markdown","source":["# Step 8: Rewriting the code by doing Model Subclassing"]},{"metadata":{"id":"Seac6FOLkwxt","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":34},"outputId":"1064db64-a013-4785-d524-d7b786616073","executionInfo":{"status":"ok","timestamp":1527510390054,"user_tz":-300,"elapsed":4800,"user":{"displayName":"Hamza Amir","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"112301600399689865426"}}},"cell_type":"code","source":["# you should define your layers in __init__ and you should implement the model's forward pass in call.\n","\n","import tensorflow as tf\n","import keras\n","class MyModel(tf.keras.Model):\n","    \n","        def __init__(self):\n","            \n","                        super(MyModel, self).__init__()\n","                        self.dense1 = Dense(60, activation=\"relu\")\n","                        self.dense2 = Dense(10, activation='relu')\n","                        self.dense3 = Dense(1, activation='sigmoid')\n","\n","        def call(self, inputs):\n","\n","                        x = self.dense1(inputs)\n","                        x = self.dense2(x)\n","                        return self.dense3(x)\n","                        \n","                    \n","model = MyModel()\n","model.compile(loss='binary_crossentropy', optimizer='adam',   metrics=['accuracy'])\n","model.fit(X,Y, epochs=20, batch_size=4,verbose=False)"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f5f19565f98>"]},"metadata":{"tags":[]},"execution_count":20}]}]}